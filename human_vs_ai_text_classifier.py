# -*- coding: utf-8 -*-
"""human vs AI text classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S8lq-NtU2XmblCPZM0Drz8A4vtA3LIUO
"""

!pip install --upgrade transformers datasets pandas scikit-learn torch

import pandas as pd
from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import torch

# --- GPU Check Block ---
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU name:", torch.cuda.get_device_name(0))

# --- Load Dataset Block ---
df = pd.read_csv("complete_dataset.csv")

# Your dataset already has numeric labels: 0 = Human, 1 = AI
# Just make sure they are integers
df["labels"] = df["label"].astype(int)

print("Unique numeric labels:", df["labels"].unique())
print("Dataset size:", len(df))

# --- Split Dataset Block ---
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    df["text"].astype(str).tolist(),
    df["labels"].tolist(),
    test_size=0.30,
    random_state=42
)

val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts,
    temp_labels,
    test_size=0.50,
    random_state=42
)

print(f"Train size: {len(train_texts)}")
print(f"Validation size: {len(val_texts)}")
print(f"Test size: {len(test_texts)}")

#--- Convert to Hugging Face Dataset Block ---
train_df = pd.DataFrame({"text": train_texts, "labels": train_labels})
val_df = pd.DataFrame({"text": val_texts, "labels": val_labels})
test_df = pd.DataFrame({"text": test_texts, "labels": test_labels})

train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)
test_dataset = Dataset.from_pandas(test_df)

# --- Tokenization Block ---
model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True, max_length=256)

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)
test_dataset = test_dataset.map(tokenize, batched=True)

# Format datasets for PyTorch
train_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
val_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
test_dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

# --- Model Block ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)

# --- Training Setup Block ---
training_args = TrainingArguments(
    output_dir="./results",
    do_eval=True,
    save_steps=500,
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=1,   # quick run; increase to 3+ for full training
    weight_decay=0.01,
    logging_steps=100,
    report_to="none"
)

def compute_metrics(eval_pred):
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support
    logits, labels = eval_pred
    preds = logits.argmax(axis=-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average="binary")
    acc = accuracy_score(labels, preds)
    return {"accuracy": acc, "f1": f1, "precision": precision, "recall": recall}

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

trainer.train()

# --- Evaluate Block ---
print("Validation Results:", trainer.evaluate(val_dataset))
print("Test Results:", trainer.evaluate(test_dataset))

# --- Prediction Block ---
def classify_text(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=256).to(device)
    outputs = model(**inputs)
    prediction = torch.argmax(outputs.logits, dim=1).item()
    return "This is human generated text" if prediction == 0 else "This is AI generated text"

# Sample Prediction
sample_text = "Would you like me to help"
print("Sample Prediction:", classify_text(sample_text))

# User Input Prediction
user_text = input("Enter a sentence to classify: ")
print("Input:", user_text)
print("Model Prediction:", classify_text(user_text))